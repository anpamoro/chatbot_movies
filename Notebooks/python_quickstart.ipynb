{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Quickstart with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/tutorials/python_quickstart\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on Google AI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOxMUKTxR-_j"
      },
      "source": [
        "This quickstart demonstrates how to use the Python SDK for the Gemini API, which gives you access to Google's Gemini large language models. In this quickstart, you will learn how to:\n",
        "\n",
        "1. Set up your development environment and API access to use Gemini.\n",
        "2. Generate text responses from text inputs.\n",
        "3. Generate text responses from multimodal inputs (text and images).\n",
        "4. Use Gemini for multi-turn conversations (chat).\n",
        "5. Use embeddings for large language models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9__zr1nSBpE"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You can run this quickstart in [Google Colab](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb), which runs this notebook directly in the browser and does not require additional environment configuration.\n",
        "\n",
        "Alternatively, to complete this quickstart locally, ensure that your development environment meets the following requirements:\n",
        "\n",
        "-  Python 3.9+\n",
        "-  An installation of `jupyter` to run the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFPBKLapSCkM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNV1e3ASJha"
      },
      "source": [
        "### Install the Python SDK\n",
        "\n",
        "The Python SDK for the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OEoeosRTv-5",
        "outputId": "c92fb923-595b-441d-e7b4-0169ec0bba7c"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCFF5VSTbcAR"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRC2HngneEeQ"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/patriciapmr/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d10c38a5c91f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Used to securely store your API key\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m userdata\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYFrFPjSGNq"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHhsUxDTdw0W"
      },
      "source": [
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `GOOGLE_API_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmSlTHXxb5pV"
      },
      "source": [
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n",
        "* Pass the key to `genai.configure(api_key=...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "ab9ASynfcIZn",
        "outputId": "6bba1777-73f1-4433-96f2-86f7dd494de7"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "import os\n",
        "GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ssbTMNVSMd-"
      },
      "source": [
        "## List models\n",
        "\n",
        "Now you're ready to call the Gemini API. Use `list_models` to see the available Gemini models:\n",
        "\n",
        "* `gemini-pro`: optimized for text-only prompts.\n",
        "* `gemini-pro-vision`: optimized for text-and-images prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QvvWFy08e5c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTl5NjtrhA0J"
      },
      "source": [
        "Note: For detailed information about the available models, including their capabilities and rate limits, see [Gemini models](https://ai.google.dev/models/gemini). There are options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\n",
        "\n",
        "The `genai` package also supports the PaLM  family of models, but only the Gemini models support the generic, multimodal capabilities of the `generateContent` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfoK3I3hu6V"
      },
      "source": [
        "## Generate text from text inputs\n",
        "\n",
        "For text-only prompts, use the `gemini-pro` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2bcfnGEviwTI"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR_2A_sxk8sK"
      },
      "source": [
        "The `generate_content` method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output.\n",
        "\n",
        "In the simplest case, you can pass a prompt string to the <a href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"><code>GenerativeModel.generate_content</code></a> method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "he-OfzBbhACQ",
        "outputId": "b2db8b2d-4dbb-48a5-8299-2c04d14900ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 9.09 ms, sys: 0 ns, total: 9.09 ms\n",
            "Wall time: 1.02 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"How many cats types are?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbrR-n_qlpFd"
      },
      "source": [
        "In simple cases, the `response.text` accessor is all you need. To display formatted Markdown text, use the `to_markdown` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "G-zBkueElVEO",
        "outputId": "b6a2ef13-cbc0-46f9-e8ac-a7dbb99d1537"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> There are 39 recognized cat breeds by The International Cat Association (TICA) and 44 by FÃ©dÃ©ration Internationale FÃ©line (FIFe)."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZPpoKMQoru8"
      },
      "source": [
        "If the API failed to return a result, use `GenerateContentRespose.prompt_feedback` to see if it was blocked due to safety concerns regarding the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eIQdU8AGoraT",
        "outputId": "bf483edc-5b90-409d-b594-8c6749f51bcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.prompt_feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEJupEDUo6Xj"
      },
      "source": [
        "Gemini can generate multiple possible responses for a single prompt. These possible responses are called `candidates`, and you can review them to select the most suitable one as the response.\n",
        "\n",
        "View the response candidates with <a href=\"https://ai.google.dev/api/python/google/ai/generativelanguage/GenerateContentResponse#candidates\"><code>GenerateContentResponse.candidates</code></a>:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QoGYz-I7o5wF",
        "outputId": "d23e8956-4cde-4904-ade2-2a46995fb730"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[index: 0\n",
              "content {\n",
              "  parts {\n",
              "    text: \"There are 39 recognized cat breeds by The International Cat Association (TICA) and 44 by FÃ©dÃ©ration Internationale FÃ©line (FIFe).\"\n",
              "  }\n",
              "  role: \"model\"\n",
              "}\n",
              "finish_reason: STOP\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJrwllLnHlBb"
      },
      "source": [
        "By default, the model returns a response after completing the entire generation process. You can also stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated.\n",
        "\n",
        "To stream responses, use <a href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"><code>GenerativeModel.generate_content(..., stream=True)</code></a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z7n59b3hHo6-",
        "outputId": "59fb2459-bce5-4ef4-e5ea-e45a2c1fb994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 5.5 ms, sys: 7.78 ms, total: 13.3 ms\n",
            "Wall time: 773 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"What is the meaning of life?\", stream=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2jt0d0GCIUhg",
        "outputId": "fb66342f-02d8-44a9-c914-e4ad3000a877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The meaning of life is a deep philosophical question that has been contemplated by humans for\n",
            "________________________________________________________________________________\n",
            " centuries. There is no single, universally accepted answer to this question, as the meaning of life is likely to be unique to each individual. However, some common\n",
            "________________________________________________________________________________\n",
            " themes that emerge in discussions about the meaning of life include:\n",
            "\n",
            "* **Finding purpose and fulfillment:** Many people find meaning in their lives by pursuing activities that bring them joy, satisfaction, and a sense of accomplishment. This can include work, hobbies, relationships, or volunteering.\n",
            "* **Making a difference in the world\n",
            "________________________________________________________________________________\n",
            ":** Others find meaning in their lives by making a positive contribution to the world. This can involve working to improve the lives of others, protecting the environment, or creating something lasting and meaningful.\n",
            "* **Living in the present moment:** Some people believe that the meaning of life is simply to be present and fully engaged in the current moment. This can involve practicing mindfulness, meditation, or simply paying attention to the beauty and wonder of the world around you.\n",
            "* **Connecting with others:** Relationships with friends, family, and loved ones can bring great meaning and purpose to life. Sharing experiences, offering support, and caring for each other can\n",
            "________________________________________________________________________________\n",
            " make us feel connected and valued.\n",
            "* **Exploring and learning:** The pursuit of knowledge and understanding can also give life meaning. This can involve reading, traveling, studying, or simply being open to new experiences.\n",
            "\n",
            "Ultimately, the meaning of life is a personal journey that each individual must discover for themselves. There is no right or wrong answer, and the meaning of life may change and evolve over time. However, by reflecting on our values, passions, and aspirations, we can all strive to live a meaningful and fulfilling life.\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "for chunk in response:\n",
        "  print(chunk.text)\n",
        "  print(\"_\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b4Hkfj-pm3p"
      },
      "source": [
        "When streaming, some response attributes are not available until you've iterated through all the response chunks. This is demonstrated below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-URRx4chp0Kt"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\"What is the meaning of life?\", stream=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HklomMEp9QM"
      },
      "source": [
        "The `prompt_feedback` attribute works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "i1BvdXjop2V-",
        "outputId": "df0a1371-a8c8-4a9a-ea39-d5f91b428b72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.prompt_feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVaFQ4RmqGOH"
      },
      "source": [
        "But attributes like <code>text</code> do not:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TiRkS6nCqFmM",
        "outputId": "e7654152-776f-4f8d-d62a-e7b909987c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IncompleteIterationError: Please let the response complete iteration before accessing the final accumulated\n",
            "attributes (or call `response.resolve()`)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  response.text\n",
        "except Exception as e:\n",
        "  print(f'{type(e).__name__}: {e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCzr5ZpNhxLm"
      },
      "source": [
        "## Generate text from image and text inputs\n",
        "\n",
        "Gemini provides a multimodal model (`gemini-pro-vision`) that accepts both text and images and inputs. The `GenerativeModel.generate_content` API is designed to handle multimodal prompts and returns a text output.\n",
        "\n",
        "Let's include an image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NtNGTBFF8Pgl",
        "outputId": "1c043ee5-2746-45cf-fa52-852c56cd8e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: no matches found: https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw\n"
          ]
        }
      ],
      "source": [
        "!curl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CjnS0vNTsVis",
        "outputId": "9d7fe55a-7624-41f1-988e-3b1cc4590aa5"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'image.jpg'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m img\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/PIL/Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image.jpg'"
          ]
        }
      ],
      "source": [
        "import PIL.Image\n",
        "\n",
        "img = PIL.Image.open('image.jpg')\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r99TN2R8EUD"
      },
      "source": [
        "Use the `gemini-pro-vision` model and pass the image to the model with `generate_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EtXxgVzmJZzE"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro-vision')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GwYifv298Cj3",
        "outputId": "17898bc6-32dc-4a2a-fcc2-c4bf1cb29f85"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'img' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(\u001b[43mimg\u001b[49m)\n\u001b[1;32m      3\u001b[0m to_markdown(response\u001b[38;5;241m.\u001b[39mtext)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(img)\n",
        "\n",
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xW2Kyra8pSz"
      },
      "source": [
        "To provide both text and images in a prompt, pass a list containing the strings and images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vm9tUYeT8lBc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'img' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mimg\u001b[49m], stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m response\u001b[38;5;241m.\u001b[39mresolve()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
          ]
        }
      ],
      "source": [
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\n",
        "response.resolve()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "d46826OA9IDS",
        "outputId": "a1f80dc8-4a77-4fb4-d6cd-7c5bddfab87c"
      },
      "outputs": [
        {
          "ename": "IncompleteIterationError",
          "evalue": "Please let the response complete iteration before accessing the final accumulated\nattributes (or call `response.resolve()`)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIncompleteIterationError\u001b[0m                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m to_markdown(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/google/generativeai/types/generation_types.py:331\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A quick accessor equivalent to `self.candidates[0].parts[0].text`\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m        ValueError: If the candidate list or parts list does not contain exactly one entry.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m     parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parts:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.text` quick accessor only works when the response contains a valid \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Part`, but none was returned. Check the `candidate.safety_ratings` to see if the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse was blocked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m         )\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/google/generativeai/types/generation_types.py:309\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.parts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparts\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A quick accessor equivalent to `self.candidates[0].parts`\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m        ValueError: If the candidate list does not contain exactly one candidate.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.parts` quick accessor only works for a single candidate, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m         )\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/google/generativeai/types/generation_types.py:299\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.candidates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The list of candidate responses.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03mRaises:\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    IncompleteIterationError: With `stream=True` if iteration over the stream was not completed.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteIterationError(_INCOMPLETE_ITERATION_MESSAGE)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mcandidates\n",
            "\u001b[0;31mIncompleteIterationError\u001b[0m: Please let the response complete iteration before accessing the final accumulated\nattributes (or call `response.resolve()`)"
          ]
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsIZmCYVTDHD"
      },
      "source": [
        "## Chat conversations\n",
        "\n",
        "Gemini enables you to have freeform conversations across multiple turns. The `ChatSession` class simplifies the process by managing the state of the conversation, so unlike with `generate_content`, you do not have to store the conversation history as a list.\n",
        "\n",
        "Initialize the chat:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "y8B9Mwo-TCr2",
        "outputId": "b0929112-a79f-4ec5-b0f3-0ae997c40d2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatSession(\n",
              "    model=genai.GenerativeModel(\n",
              "        model_name='models/gemini-pro',\n",
              "        generation_config={},\n",
              "        safety_settings={},\n",
              "        tools=None,\n",
              "    ),\n",
              "    history=[]\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat(history=[])\n",
        "chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Il02N-km9j"
      },
      "source": [
        "Note: The vision model `gemini-pro-vision` is not optimized for multi-turn chat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5odluV7kKbgr"
      },
      "source": [
        "The `ChatSession.send_message` method returns the same `GenerateContentResponse` type as <a href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"><code>GenerativeModel.generate_content</code></a>. It also appends your message and the response to the chat history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "b72zbOEjKRxP",
        "outputId": "e84d7f72-e2bb-43ea-d5f5-b8aafa22ad91"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> A computer is a magic box that can store information, show pictures, play games, and do math just like a smart helper."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.send_message(\"In one sentence, explain how a computer works to a young child.\")\n",
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5-5HS2bTOTU9",
        "outputId": "1b5c7572-67b5-4715-cb24-e1b6a4b3a982"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"In one sentence, explain how a computer works to a young child.\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"A computer is a magic box that can store information, show pictures, play games, and do math just like a smart helper.\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JaiFSIvOcVb"
      },
      "source": [
        "You can keep sending messages to continue the conversation. Use the `stream=True` argument to stream the chat:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Vxku7mzSObfZ",
        "outputId": "6247e3fc-1f57-47f2-d164-74616a1b73f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A computer is an electronic device that can be programmed to carry out a set of\n",
            "________________________________________________________________________________\n",
            " instructions. It consists of hardware, which are the physical components of the computer, and software, which are the programs that run on the hardware. The hardware includes\n",
            "________________________________________________________________________________\n",
            " the central processing unit (CPU), which is the \"brain\" of the computer and controls all of its operations; the memory, which stores data and instructions; the storage devices, such as hard drives and solid-state drives, which store data permanently; and the input and output devices, such as keyboards, mice,\n",
            "________________________________________________________________________________\n",
            " monitors, and printers, which allow the user to interact with the computer. The software includes the operating system, which manages the hardware and provides basic services to other software; application software, which performs specific tasks, such as word processing, spreadsheets, and games; and system software, which provides support for application software and the operating system.\n",
            "\n",
            "In summary, a computer is a powerful tool that can be used to perform a wide range of tasks, from simple calculations to complex simulations. It consists of hardware and software that work together to carry out instructions and process data.\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "response = chat.send_message(\"Okay, how about a more detailed explanation to a high schooler?\", stream=True)\n",
        "\n",
        "for chunk in response:\n",
        "  print(chunk.text)\n",
        "  print(\"_\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwCqtZ6D4kvk"
      },
      "source": [
        "`glm.Content` objects contain a list of `glm.Part` objects that each contain either a text (string) or inline_data (`glm.Blob`), where a blob contains binary data and a `mime_type`. The chat history is available as a list of `glm.Content` objects in `ChatSession.history`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WvyTmbC2d0k3",
        "outputId": "bc9fafa1-9f08-43ff-da70-784e8a8675ad"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> **user**: In one sentence, explain how a computer works to a young child."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "> **model**: A computer is a magic box that can store information, show pictures, play games, and do math just like a smart helper."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "> **user**: Okay, how about a more detailed explanation to a high schooler?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "> **model**: A computer is an electronic device that can be programmed to carry out a set of instructions. It consists of hardware, which are the physical components of the computer, and software, which are the programs that run on the hardware. The hardware includes the central processing unit (CPU), which is the \"brain\" of the computer and controls all of its operations; the memory, which stores data and instructions; the storage devices, such as hard drives and solid-state drives, which store data permanently; and the input and output devices, such as keyboards, mice, monitors, and printers, which allow the user to interact with the computer. The software includes the operating system, which manages the hardware and provides basic services to other software; application software, which performs specific tasks, such as word processing, spreadsheets, and games; and system software, which provides support for application software and the operating system.\n",
              "> \n",
              "> In summary, a computer is a powerful tool that can be used to perform a wide range of tasks, from simple calculations to complex simulations. It consists of hardware and software that work together to carry out instructions and process data."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEgVOYu0pAr4"
      },
      "source": [
        "## Count tokens\n",
        "\n",
        "Large language models have a context window, and the context length is often measured in terms of the **number of tokens**. With the Gemini API, you can determine the number of tokens per any `glm.Content` object. In the simplest case, you can pass a query string to the `GenerativeModel.count_tokens` method as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "eLjBmPCLpElk",
        "outputId": "c627a361-8178-4f84-c960-26683ab12014"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "total_tokens: 7"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.count_tokens(\"What is the meaning of life?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM2_U8pmpHQA"
      },
      "source": [
        "Similarly, you can check `token_count` for your `ChatSession`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "i0MUU4BZpG4_",
        "outputId": "a19353e1-c243-4b1a-9e47-7c8c91f5dde8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "total_tokens: 283"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.count_tokens(chat.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9bU0J3vUIbz"
      },
      "source": [
        "## Use embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpHIRU5bj7aW"
      },
      "source": [
        "[Embedding](https://developers.google.com/machine-learning/glossary#embedding-vector) is a technique used to represent information as a list of floating point numbers in an array. With Gemini, you can represent text (words, sentences, and blocks of text) in a vectorized form, making it easier to compare and contrast embeddings. For example, two texts that share a similar subject matter or sentiment should have similar embeddings, which can be identified through mathematical comparison techniques such as cosine similarity. For more on how and why you should use embeddings, refer to the [Embeddings guide](https://ai.google.dev/docs/embeddings_guide).\n",
        "\n",
        "Use the `embed_content` method to generate embeddings. The method handles embedding for the following tasks (`task_type`):\n",
        "\n",
        "Task Type | Description\n",
        "---       | ---\n",
        "RETRIEVAL_QUERY\t| Specifies the given text is a query in a search/retrieval setting.\n",
        "RETRIEVAL_DOCUMENT | Specifies the given text is a document in a search/retrieval setting. Using this task type requires a `title`.\n",
        "SEMANTIC_SIMILARITY\t| Specifies the given text will be used for Semantic Textual Similarity (STS).\n",
        "CLASSIFICATION\t| Specifies that the embeddings will be used for classification.\n",
        "CLUSTERING\t| Specifies that the embeddings will be used for clustering.\n",
        "\n",
        "The following generates an embedding for a single string for document retrieval:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hskqSKnJUHvp",
        "outputId": "52f3b329-5818-46d5-b9b2-f4bbaca175fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.003216741, -0.013358698, -0.017649598, -0.0091 ... TRIMMED]\n"
          ]
        }
      ],
      "source": [
        "result = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=\"What is the meaning of life?\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of single string\")\n",
        "\n",
        "# 1 input > 1 vector output\n",
        "print(str(result['embedding'])[:50], '... TRIMMED]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcSc3KfflBCQ"
      },
      "source": [
        "Note: The `retrieval_document` task type is the only task that accepts a title.\n",
        "\n",
        "To handle batches of strings, pass a list of strings in `content`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OnyD-Joik8LE",
        "outputId": "49507977-b996-46b8-c430-57f4a48c01c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0040260437, 0.004124458, -0.014209415, -0.00183 ... TRIMMED ...\n",
            "[-0.004049845, -0.0075574904, -0.0073463684, -0.03 ... TRIMMED ...\n",
            "[0.025310587, -0.0080734305, -0.029902633, 0.01160 ... TRIMMED ...\n"
          ]
        }
      ],
      "source": [
        "result = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=[\n",
        "      'What is the meaning of life?',\n",
        "      'How much wood would a woodchuck chuck?',\n",
        "      'How does the brain work?'],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of list of strings\")\n",
        "\n",
        "# A list of inputs > A list of vectors output\n",
        "for v in result['embedding']:\n",
        "  print(str(v)[:50], '... TRIMMED ...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBg0eNeml3d4"
      },
      "source": [
        "While the `genai.embed_content` function accepts simple strings or lists of strings, it is actually built around the `glm.Content` type (like <a href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"><code>GenerativeModel.generate_content</code></a>). `glm.Content` objects are the primary units of conversation in the API.\n",
        "\n",
        "While the `glm.Content` object is multimodal, the `embed_content` method only supports text embeddings. This design gives the API the *possibility* to expand to multimodal embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1-wmapZznXrm",
        "outputId": "0b386261-ab44-47b5-8c17-1c3acec45ccb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "parts {\n",
              "  text: \"A computer is an electronic device that can be programmed to carry out a set of instructions. It consists of hardware, which are the physical components of the computer, and software, which are the programs that run on the hardware. The hardware includes the central processing unit (CPU), which is the \\\"brain\\\" of the computer and controls all of its operations; the memory, which stores data and instructions; the storage devices, such as hard drives and solid-state drives, which store data permanently; and the input and output devices, such as keyboards, mice, monitors, and printers, which allow the user to interact with the computer. The software includes the operating system, which manages the hardware and provides basic services to other software; application software, which performs specific tasks, such as word processing, spreadsheets, and games; and system software, which provides support for application software and the operating system.\\n\\nIn summary, a computer is a powerful tool that can be used to perform a wide range of tasks, from simple calculations to complex simulations. It consists of hardware and software that work together to carry out instructions and process data.\"\n",
              "}\n",
              "role: \"model\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.candidates[0].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "cvX5jsrcnufk",
        "outputId": "eb175cdf-75e9-4480-f2e6-5b239c21626c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.015892413, -0.03422503, 0.009384803, 0.0207892 ... TRIMMED ...\n"
          ]
        }
      ],
      "source": [
        "result = genai.embed_content(\n",
        "    model = 'models/embedding-001',\n",
        "    content = response.candidates[0].content)\n",
        "\n",
        "# 1 input > 1 vector output\n",
        "print(str(result['embedding'])[:50], '... TRIMMED ...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU8juHCxoUKG"
      },
      "source": [
        "Similarly, the chat history contains a list of `glm.Content` objects, which you can pass directly to the `embed_content` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ur5ajPsdnCON",
        "outputId": "1601789f-a381-442e-de15-2721b48f4722"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"In one sentence, explain how a computer works to a young child.\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"A computer is a magic box that can store information, show pictures, play games, and do math just like a smart helper.\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Okay, how about a more detailed explanation to a high schooler?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"A computer is an electronic device that can be programmed to carry out a set of instructions. It consists of hardware, which are the physical components of the computer, and software, which are the programs that run on the hardware. The hardware includes the central processing unit (CPU), which is the \\\"brain\\\" of the computer and controls all of its operations; the memory, which stores data and instructions; the storage devices, such as hard drives and solid-state drives, which store data permanently; and the input and output devices, such as keyboards, mice, monitors, and printers, which allow the user to interact with the computer. The software includes the operating system, which manages the hardware and provides basic services to other software; application software, which performs specific tasks, such as word processing, spreadsheets, and games; and system software, which provides support for application software and the operating system.\\n\\nIn summary, a computer is a powerful tool that can be used to perform a wide range of tasks, from simple calculations to complex simulations. It consists of hardware and software that work together to carry out instructions and process data.\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Z3xDB1hwof96",
        "outputId": "9cc3dc31-4e6e-463f-8c10-243e41b6c90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.014632266, -0.042202696, -0.015757175, 0.01548 ... TRIMMED...\n",
            "[-0.033597015, -0.0116623845, -0.022904681, 0.0123 ... TRIMMED...\n",
            "[-0.010055617, -0.07208932, -0.00011750793, -0.023 ... TRIMMED...\n",
            "[-0.015892413, -0.03422503, 0.009384803, 0.0207892 ... TRIMMED...\n"
          ]
        }
      ],
      "source": [
        "result = genai.embed_content(\n",
        "    model = 'models/embedding-001',\n",
        "    content = chat.history)\n",
        "\n",
        "# 1 input > 1 vector output\n",
        "for i,v in enumerate(result['embedding']):\n",
        "  print(str(v)[:50], '... TRIMMED...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuz9-TWDzdlb"
      },
      "source": [
        "## Advanced use cases\n",
        "\n",
        "The following sections discuss advanced use cases and lower-level details of the Python SDK for the Gemini API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5FWJPSD1qFE"
      },
      "source": [
        "### Safety settings\n",
        "\n",
        "The `safety_settings` argument lets you configure what the model blocks and allows in both prompts and responses. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about [Safety settings](https://ai.google.dev/docs/safety_setting).\n",
        "\n",
        "Enter a questionable prompt and run the model with the default safety settings, and it will not return any candidates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "VR1fp12I1yH0",
        "outputId": "831a98ca-2bb0-4d3e-f62c-719c6162c766"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[index: 0\n",
              "finish_reason: SAFETY\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: HIGH\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = model.generate_content('[Questionable prompt here]')\n",
        "response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31Q8kAItGLOU"
      },
      "source": [
        "The `prompt_feedback` will tell you which safety filter blocked the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GMUvWNkZ11x4",
        "outputId": "48aa0b85-2ec9-410f-ce24-316608557cd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.prompt_feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtPC1Fo514ec"
      },
      "source": [
        "Now provide the same prompt to the model with newly configured safety settings, and you may get a response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "0UIt5LKp16jL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I'm so sorry, but I can't answer this question. It is inappropriate and harmful to make generalizations about entire groups of people.\""
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = model.generate_content('[Questionable prompt here]',\n",
        "                                  safety_settings={'HARASSMENT':'block_none'})\n",
        "response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE_f5EruGUnj"
      },
      "source": [
        "Also note that each candidate has its own `safety_ratings`, in case the prompt passes but the individual responses fail the safety checks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipa-8leY6wsK"
      },
      "source": [
        "### Encode messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r47nsUOn6YY"
      },
      "source": [
        "The previous sections relied on the SDK to make it easy for you to send prompts to the API. This section offers a fully-typed equivalent to the previous example, so you can better understand the lower-level details regarding how the SDK encodes messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fthdIItnqki"
      },
      "source": [
        "Underlying the Python SDK is the <a href=\"https://ai.google.dev/api/python/google/ai/generativelanguage\"><code>google.ai.generativelanguage</code></a> client library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "l6aafWECnpX6"
      },
      "outputs": [],
      "source": [
        "import google.ai.generativelanguage as glm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm1RWcB3n_n0"
      },
      "source": [
        "The SDK attempts to convert your message to a `glm.Content` object, which contains a list of `glm.Part` objects that each contain either:\n",
        "\n",
        "1. a <a href=\"https://www.tensorflow.org/text/api_docs/python/text\"><code>text</code></a> (string)\n",
        "2. `inline_data` (`glm.Blob`), where a blob contains binary `data` and a `mime_type`.\n",
        "\n",
        "You can also pass any of these classes as an equivalent dictionary.\n",
        "\n",
        "Note: The only accepted mime types are some image types, `image/*`.\n",
        "\n",
        "So, the fully-typed equivalent to the previous example is:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "IqFXdgDFRvlU"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'image.jpg'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[50], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini-pro-vision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m      3\u001b[0m     glm\u001b[38;5;241m.\u001b[39mContent(\n\u001b[1;32m      4\u001b[0m         parts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m             glm\u001b[38;5;241m.\u001b[39mPart(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a short, engaging blog post based on this picture.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m             glm\u001b[38;5;241m.\u001b[39mPart(\n\u001b[1;32m      7\u001b[0m                 inline_data\u001b[38;5;241m=\u001b[39mglm\u001b[38;5;241m.\u001b[39mBlob(\n\u001b[1;32m      8\u001b[0m                     mime_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage/jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 9\u001b[0m                     data\u001b[38;5;241m=\u001b[39m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m                 )\n\u001b[1;32m     11\u001b[0m             ),\n\u001b[1;32m     12\u001b[0m         ],\n\u001b[1;32m     13\u001b[0m     ),\n\u001b[1;32m     14\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/pathlib.py:1126\u001b[0m, in \u001b[0;36mPath.read_bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;124;03m    Open the file in bytes mode, read it, and close the file.\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/pathlib.py:1119\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1118\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image.jpg'"
          ]
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-pro-vision')\n",
        "response = model.generate_content(\n",
        "    glm.Content(\n",
        "        parts = [\n",
        "            glm.Part(text=\"Write a short, engaging blog post based on this picture.\"),\n",
        "            glm.Part(\n",
        "                inline_data=glm.Blob(\n",
        "                    mime_type='image/jpeg',\n",
        "                    data=pathlib.Path('image.jpg').read_bytes()\n",
        "                )\n",
        "            ),\n",
        "        ],\n",
        "    ),\n",
        "    stream=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKithEbeRzDX",
        "outputId": "a92f5c53-8124-4e44-ada1-b0f1c5aba293"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              ">  Meal prepping is a great way to save time and money, and it can also help you to eat healthier. By ... [TRIMMED] ..."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.resolve()\n",
        "\n",
        "to_markdown(response.text[:100] + \"... [TRIMMED] ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBqknExlzn0k"
      },
      "source": [
        "### Multi-turn conversations\n",
        "\n",
        "While the `genai.ChatSession` class shown earlier can handle many use cases, it does make some assumptions. If your use case doesn't fit into this chat implementation it's good to remember that `genai.ChatSession` is just a wrapper around <a href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"><code>GenerativeModel.generate_content</code></a>. In addition to single requests, it can handle multi-turn conversations.\n",
        "\n",
        "The individual messages are `glm.Content` objects or compatible dictionaries, as seen in previous sections. As a dictionary, the message requires `role` and `parts` keys. The `role` in a conversation can either be the `user`, which provides the prompts, or `model`, which provides the responses.\n",
        "\n",
        "Pass a list of `glm.Content` objects and it will be treated as multi-turn chat:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "LtfwMa0HzvZL",
        "outputId": "9874e9f3-e405-4468-80c4-5e0b43de2df0"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> Imagine a magic box called a computer. Inside, it has tiny helpers called processors that are like super-fast brains.\n",
              "> \n",
              "> When you click a button on the computer, the processors receive the message. They rush to find the information you need and send it to a screen called a monitor.\n",
              "> \n",
              "> Just like a TV shows you videos, the monitor shows you the information the processors found. And if you want to type something, you use a keyboard. The keyboard sends the letters you type to the processors, and they put them on the screen."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "messages = [\n",
        "    {'role':'user',\n",
        "     'parts': [\"Briefly explain how a computer works to a young child.\"]}\n",
        "]\n",
        "response = model.generate_content(messages)\n",
        "\n",
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mqqiDJvzyac"
      },
      "source": [
        "To continue the conversation, add the response and another message.\n",
        "\n",
        "Note: For multi-turn conversations, you need to send the whole conversation history with each request. The API is **stateless**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "MBxsZBxcz5Ik",
        "outputId": "56998273-7b9e-449b-f129-8b041cb18fa4"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> **How a Computer Works: A Detailed Explanation**\n",
              "> \n",
              "> A computer is an electronic device that can be programmed to carry out a set of instructions. It consists of hardware and software.\n",
              "> \n",
              "> **Hardware** is the physical components of a computer, such as the processor, memory, storage devices, input devices (e.g., keyboard, mouse), and output devices (e.g., monitor, printer).\n",
              "> \n",
              "> **Software** is the set of instructions that tells the computer what to do. It includes the operating system, which manages the computer's resources, and application software, which performs specific tasks (e.g., word processing, web browsing).\n",
              "> \n",
              "> **How a Computer Executes Instructions**\n",
              "> \n",
              "> 1. **Fetch:** The processor fetches the next instruction from memory.\n",
              "> 2. **Decode:** The processor decodes the instruction to determine what action to perform.\n",
              "> 3. **Execute:** The processor executes the instruction.\n",
              "> 4. **Store:** The processor stores the results of the instruction in memory.\n",
              "> \n",
              "> **Components of a Computer**\n",
              "> \n",
              "> * **Processor (CPU):** The brain of the computer that executes instructions.\n",
              "> * **Memory (RAM):** Stores data and instructions that are currently being processed.\n",
              "> * **Storage Devices (HDD, SSD):** Stores data permanently, even when the computer is turned off.\n",
              "> * **Input Devices:** Allow the user to interact with the computer, such as keyboard, mouse, and scanner.\n",
              "> * **Output Devices:** Display or print information, such as monitor and printer.\n",
              "> \n",
              "> **How Computers Are Used**\n",
              "> \n",
              "> Computers are used for a wide variety of tasks, including:\n",
              "> \n",
              "> * Word processing\n",
              "> * Web browsing\n",
              "> * Email\n",
              "> * Gaming\n",
              "> * Social networking\n",
              "> * Data analysis\n",
              "> * Scientific research\n",
              "> * Business applications\n",
              "> \n",
              "> **Example of a Computer Task**\n",
              "> \n",
              "> When you type a document in a word processor, the following steps occur:\n",
              "> \n",
              "> 1. You press a key on the keyboard.\n",
              "> 2. The keyboard sends a signal to the computer.\n",
              "> 3. The processor receives the signal and fetches the appropriate instruction from memory.\n",
              "> 4. The processor decodes the instruction and executes it, which causes the letter to be displayed on the screen.\n",
              "> 5. The processor stores the letter in memory.\n",
              "> \n",
              "> This process is repeated for each keystroke, until the document is complete."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages.append({'role':'model',\n",
        "                 'parts':[response.text]})\n",
        "\n",
        "messages.append({'role':'user',\n",
        "                 'parts':[\"Okay, how about a more detailed explanation to a high school student?\"]})\n",
        "\n",
        "response = model.generate_content(messages)\n",
        "\n",
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4spL8SJ10ir7"
      },
      "source": [
        "### Generation configuration\n",
        "\n",
        "The `generation_config` argument allows you to modify the generation parameters. Every prompt you send to the model includes parameter values that control how the model generates responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gE7I9Anl0ud7"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "response = model.generate_content(\n",
        "    'Tell me a story about a magic backpack.',\n",
        "    generation_config=genai.types.GenerationConfig(\n",
        "        # Only one candidate for now.\n",
        "        candidate_count=1,\n",
        "        stop_sequences=['x'],\n",
        "        max_output_tokens=20,\n",
        "        temperature=1.0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "0fbab01e8fcf",
        "outputId": "0bf37e13-d571-4d41-9e40-76aab667eb94"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfinish_reason\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAX_TOKENS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/google/generativeai/types/generation_types.py:333\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parts:\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.text` quick accessor only works when the response contains a valid \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Part`, but none was returned. Check the `candidate.safety_ratings` to see if the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse was blocked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m     )\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m parts[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `response.text` quick accessor only works for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple (single-`Part`) text responses. This response is not simple text. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked."
          ]
        }
      ],
      "source": [
        "text = response.text\n",
        "\n",
        "if response.candidates[0].finish_reason.name == \"MAX_TOKENS\":\n",
        "    text += '...'\n",
        "\n",
        "to_markdown(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qt6Yj2JRf-0"
      },
      "source": [
        "## What's next\n",
        "\n",
        "-   Prompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for [prompt writing](https://ai.google.dev/docs/prompt_best_practices).\n",
        "-   Gemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available [Gemini models](https://ai.google.dev/models/gemini).\n",
        "-   Gemini offers options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "python_quickstart.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
