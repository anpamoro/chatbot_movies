{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8359fbd-b9f3-484e-894b-5ee6ac13bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1724414d-5c12-47c6-9a2f-ac76ecabfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "import os\n",
    "GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68630d0e-5241-4e98-85ee-e1be35218c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ba89b5-0e41-481c-b8e1-1289c3ba5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d31062b-d4b3-4983-a69a-1d724f8cfe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"How many cats types are?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f278e40-1ca8-4642-9f23-e3e081866cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> There are over 70 recognized breeds of domestic cats."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2218ed2b-dfef-4b14-8832-aa8419ec700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536c05c-8202-491b-a9f9-7cb23833fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9863a-cfdd-44c0-b878-7f56497f814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c09687-4aa1-40fd-b49d-950c073a8ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e20f3beb-ed91-4986-a228-06d47dc573db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86093dd0-3d8e-4d47-abc8-4dfcccd57ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826eb5e0-b2bf-4cee-a5fa-395d597849c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79688b3e-01c4-46ce-8a2e-58b70ee36320",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GoogleGenerativeAIEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create the open-source embedding function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mGoogleGenerativeAIEmbeddings\u001b[49m(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/embedding-001\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GoogleGenerativeAIEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "# create the open-source embedding function\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33dc6927-f9b7-4792-a0a2-0eb638a46699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query it\n",
    "query = \"what is stars wars about?\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e89054e4-2d44-4e7c-b21b-f43a5229724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from disk\n",
    "db = Chroma(persist_directory=\"./raw_data/chroma_db\", embedding_function=embeddings)\n",
    "docs = db.similarity_search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "719db0d1-76d3-46a3-984e-01288c4840fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.chroma.Chroma object at 0x7fee7b8c5720>\n"
     ]
    }
   ],
   "source": [
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a7522f6-cbc9-41f4-962d-8c9d34114102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='This movie stars Barbie as a teenage girl, trying to deal with crushes, rivals and friendship as she tries to achieve her dream of working as a news anchor for her school\\'s TV station. She doesn\\'t always make the right decisions, but she\\'s a nice enough character and considerably less \"perfect\" than she is portrayed in her other films.', metadata={'date': 2006.0, 'description': 'This movie stars Barbie as a teenage girl, trying to deal with crushes, rivals and friendship as she tries to achieve her dream of working as a news anchor for her school\\'s TV station. She doesn\\'t always make the right decisions, but she\\'s a nice enough character and considerably less \"perfect\" than she is portrayed in her other films.', 'minute': 70.0, 'name': 'The Barbie Diaries', 'rating': 3.07}), Document(page_content='This movie stars Barbie as a teenage girl, trying to deal with crushes, rivals and friendship as she tries to achieve her dream of working as a news anchor for her school\\'s TV station. She doesn\\'t always make the right decisions, but she\\'s a nice enough character and considerably less \"perfect\" than she is portrayed in her other films.', metadata={'date': 2006.0, 'description': 'This movie stars Barbie as a teenage girl, trying to deal with crushes, rivals and friendship as she tries to achieve her dream of working as a news anchor for her school\\'s TV station. She doesn\\'t always make the right decisions, but she\\'s a nice enough character and considerably less \"perfect\" than she is portrayed in her other films.', 'minute': 70.0, 'name': 'The Barbie Diaries', 'rating': 3.07}), Document(page_content='This movie stars Barbie as a teenage girl, trying to deal with crushes, rivals and friendship as she tries to achieve her dream of working as a news anchor for her school\\'s TV station. She doesn\\'t always make the right decisions, but she\\'s a nice enough character and considerably less \"perfect\" than she is portrayed in her other films.', metadata={'date': 2006.0, 'description': 'This movie stars Barbie as a teenage girl, trying to deal with crushes, rivals and friendship as she tries to achieve her dream of working as a news anchor for her school\\'s TV station. She doesn\\'t always make the right decisions, but she\\'s a nice enough character and considerably less \"perfect\" than she is portrayed in her other films.', 'minute': 70.0, 'name': 'The Barbie Diaries', 'rating': 3.07}), Document(page_content='This movie stars Barbie as a teenage girl, trying to deal with crushes, rivals and friendship as she tries to achieve her dream of working as a news anchor for her school\\'s TV station. She doesn\\'t always make the right decisions, but she\\'s a nice enough character and considerably less \"perfect\" than she is portrayed in her other films.', metadata={'date': 2006.0, 'description': 'This movie stars Barbie as a teenage girl, trying to deal with crushes, rivals and friendship as she tries to achieve her dream of working as a news anchor for her school\\'s TV station. She doesn\\'t always make the right decisions, but she\\'s a nice enough character and considerably less \"perfect\" than she is portrayed in her other films.', 'minute': 70.0, 'name': 'The Barbie Diaries', 'rating': 3.07})]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7856cc33-9f0f-4962-9b54-d504a2e4b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e57e727c-9381-4f16-b71d-74e756d6099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "  Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "  provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "  Context:\\n {context}?\\n\n",
    "  Question: \\n{question}\\n\n",
    "\n",
    "  Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a9d8bba-5782-4da4-9851-b8797d9241ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76b8c507-7fff-4d53-97b9-02cc623cc3b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mload_qa_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstuff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/langchain/chains/question_answering/__init__.py:249\u001b[0m, in \u001b[0;36mload_qa_chain\u001b[0;34m(llm, chain_type, verbose, callback_manager, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chain_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loader_mapping:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unsupported chain type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloader_mapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m     )\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchain_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/langchain/chains/question_answering/__init__.py:73\u001b[0m, in \u001b[0;36m_load_stuff_chain\u001b[0;34m(llm, prompt, document_variable_name, verbose, callback_manager, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_stuff_chain\u001b[39m(\n\u001b[1;32m     64\u001b[0m     llm: BaseLanguageModel,\n\u001b[1;32m     65\u001b[0m     prompt: Optional[BasePromptTemplate] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StuffDocumentsChain:\n\u001b[1;32m     72\u001b[0m     _prompt \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;129;01mor\u001b[39;00m stuff_prompt\u001b[38;5;241m.\u001b[39mPROMPT_SELECTOR\u001b[38;5;241m.\u001b[39mget_prompt(llm)\n\u001b[0;32m---> 73\u001b[0m     llm_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# TODO: document prompt\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StuffDocumentsChain(\n\u001b[1;32m     82\u001b[0m         llm_chain\u001b[38;5;241m=\u001b[39mllm_chain,\n\u001b[1;32m     83\u001b[0m         document_variable_name\u001b[38;5;241m=\u001b[39mdocument_variable_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     88\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/langchain_core/load/serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/chatbot_movies/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)"
     ]
    }
   ],
   "source": [
    "chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8875d28-ba41-4001-855c-b2ccff573f32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m(\n\u001b[1;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m:docs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question}\n\u001b[1;32m      3\u001b[0m     , return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chain' is not defined"
     ]
    }
   ],
   "source": [
    "response = chain(\n",
    "    {\"input_documents\":docs, \"question\": question}\n",
    "    , return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45caf2ab-4ee9-479d-aaa9-218a3ff12e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para enviar una pregunta al modelo Gemini-Pro y obtener una respuesta\n",
    "def get_gemini_response(question, context):\n",
    "    # Crea una solicitud de consulta\n",
    "    request = gemini.QueryRequest(\n",
    "        model=model,\n",
    "        query_input={\n",
    "            \"text\": question,\n",
    "            \"context\": context\n",
    "        }\n",
    "    )\n",
    "    # Envía la solicitud y obtén la respuesta\n",
    "    response = client.query(request=request)\n",
    "    \n",
    "    # Retorna la respuesta\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef4e9791-bffa-4b85-afa6-5ceebaa3f74b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gemini' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m¿Qué películas están disponibles?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m context \u001b[38;5;241m=\u001b[39m docs\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_gemini_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRespuesta del modelo Gemini-Pro:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39manswer)\n",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m, in \u001b[0;36mget_gemini_response\u001b[0;34m(question, context)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gemini_response\u001b[39m(question, context):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Crea una solicitud de consulta\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mgemini\u001b[49m\u001b[38;5;241m.\u001b[39mQueryRequest(\n\u001b[1;32m      5\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      6\u001b[0m         query_input\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: question,\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\n\u001b[1;32m      9\u001b[0m         }\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Envía la solicitud y obtén la respuesta\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gemini' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"¿Qué películas están disponibles?\"\n",
    "context = docs\n",
    "\n",
    "response = get_gemini_response(question, context)\n",
    "print(\"Respuesta del modelo Gemini-Pro:\", response.result.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc188b-cc56-47dd-9205-20ac40e09d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chroma_data('raw_data/chroma_db'):\n",
    "    data = {}\n",
    "    for filename in os.listdir(raw_data/chroma_db):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            data[filename] = df\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a8773-b7a0-4535-8fda-9dcad3b2a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import gemini_v1beta1 as gemini\n",
    "\n",
    "# Crea un cliente para la API de Gemini\n",
    "client = gemini.GeminiClient()\n",
    "\n",
    "# Define una función para enviar una pregunta al modelo Gemini-Pro y obtener una respuesta\n",
    "def get_gemini_response(question, context):\n",
    "    # Crea una solicitud de consulta\n",
    "    request = gemini.QueryRequest(\n",
    "        model=\"projects/your-project/locations/global/models/gemini-pro\",\n",
    "        query_input={\n",
    "            \"text\": question,\n",
    "            \"context\": context\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Envía la solicitud y obtén la respuesta\n",
    "    response = client.query(request=request)\n",
    "    \n",
    "    # Retorna la respuesta\n",
    "    return response\n",
    "\n",
    "# Ejemplo de uso\n",
    "question = \"¿Qué películas están disponibles en chroma_db?\"\n",
    "context = \"En la carpeta chroma_db se encuentran datos sobre películas.\"\n",
    "\n",
    "response = get_gemini_response(question, context)\n",
    "print(\"Respuesta del modelo Gemini-Pro:\", response.result.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258909ab-ab68-4b76-8fd7-ea36e007c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import gemini_v1beta1 as gemini\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Carga los datos desde la carpeta chroma_db\n",
    "def load_chroma_data(folder_path):\n",
    "    data = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            data[filename] = df\n",
    "    return data\n",
    "\n",
    "# Crea un cliente para la API de Gemini\n",
    "client = gemini.GeminiClient()\n",
    "\n",
    "# Define una función para enviar una pregunta al modelo Gemini-Pro y obtener una respuesta\n",
    "def get_gemini_response(question, context):\n",
    "    # Crea una solicitud de consulta\n",
    "    request = gemini.QueryRequest(\n",
    "        model=\"projects/your-project/locations/global/models/gemini-pro\",\n",
    "        query_input={\n",
    "            \"text\": question,\n",
    "            \"context\": context\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Envía la solicitud y obtén la respuesta\n",
    "    response = client.query(request=request)\n",
    "    \n",
    "    # Retorna la respuesta\n",
    "    return response\n",
    "\n",
    "# Ejemplo de uso\n",
    "chroma_data = load_chroma_data(\"chroma_db\")\n",
    "context = chroma_data  # Puedes ajustar esto según cómo quieras estructurar el contexto\n",
    "\n",
    "question = \"¿Cuál es la película más valorada?\"\n",
    "response = get_gemini_response(question, context)\n",
    "print(\"Respuesta del modelo Gemini-Pro:\", response.result.answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
